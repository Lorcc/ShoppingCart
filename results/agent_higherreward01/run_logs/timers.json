{
    "name": "root",
    "gauges": {
        "MoveToGoal.Policy.Entropy.mean": {
            "value": 1.9186511039733887,
            "min": 1.631839394569397,
            "max": 2.138143301010132,
            "count": 72
        },
        "MoveToGoal.Policy.Entropy.sum": {
            "value": 96055.3515625,
            "min": 81650.71875,
            "max": 107206.0859375,
            "count": 72
        },
        "MoveToGoal.Step.mean": {
            "value": 3599990.0,
            "min": 49936.0,
            "max": 3599990.0,
            "count": 72
        },
        "MoveToGoal.Step.sum": {
            "value": 3599990.0,
            "min": 49936.0,
            "max": 3599990.0,
            "count": 72
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.2480195164680481,
            "min": -0.6171987056732178,
            "max": -0.16154661774635315,
            "count": 72
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": -198.41561889648438,
            "min": -493.75897216796875,
            "max": -128.5911102294922,
            "count": 72
        },
        "MoveToGoal.Losses.PolicyLoss.mean": {
            "value": 0.06511901453482515,
            "min": 0.0631669129555424,
            "max": 0.07211088635919534,
            "count": 72
        },
        "MoveToGoal.Losses.PolicyLoss.sum": {
            "value": 3.060593683136782,
            "min": 2.4366857089892484,
            "max": 3.2228096181061123,
            "count": 72
        },
        "MoveToGoal.Losses.ValueLoss.mean": {
            "value": 0.00016840752135036365,
            "min": 3.731028064126241e-05,
            "max": 0.024041943355483448,
            "count": 72
        },
        "MoveToGoal.Losses.ValueLoss.sum": {
            "value": 0.007915153503467092,
            "min": 0.0017535831901393333,
            "max": 1.1059293943522386,
            "count": 72
        },
        "MoveToGoal.Policy.LearningRate.mean": {
            "value": 3.189329043276277e-05,
            "min": 3.189329043276277e-05,
            "max": 0.0002981242339585889,
            "count": 72
        },
        "MoveToGoal.Policy.LearningRate.sum": {
            "value": 0.00149898465033985,
            "min": 0.00149898465033985,
            "max": 0.010893385268871597,
            "count": 72
        },
        "MoveToGoal.Policy.Epsilon.mean": {
            "value": 0.1106310670212766,
            "min": 0.1106310670212766,
            "max": 0.19937474444444442,
            "count": 72
        },
        "MoveToGoal.Policy.Epsilon.sum": {
            "value": 5.199660150000001,
            "min": 5.199660150000001,
            "max": 7.959464025,
            "count": 72
        },
        "MoveToGoal.Policy.Beta.mean": {
            "value": 0.0031982569996808507,
            "min": 0.0031982569996808507,
            "max": 0.029812485858888887,
            "count": 72
        },
        "MoveToGoal.Policy.Beta.sum": {
            "value": 0.150318078985,
            "min": 0.150318078985,
            "max": 1.0893454071600002,
            "count": 72
        },
        "MoveToGoal.Environment.EpisodeLength.mean": {
            "value": 1999.0,
            "min": 1869.0,
            "max": 1999.0,
            "count": 72
        },
        "MoveToGoal.Environment.EpisodeLength.sum": {
            "value": 49975.0,
            "min": 41979.0,
            "max": 56516.0,
            "count": 72
        },
        "MoveToGoal.Environment.CumulativeReward.mean": {
            "value": -4.941520348787308,
            "min": -10.545846836068309,
            "max": -4.574920336008072,
            "count": 72
        },
        "MoveToGoal.Environment.CumulativeReward.sum": {
            "value": -123.5380087196827,
            "min": -282.02751847729087,
            "max": -104.0000073723495,
            "count": 72
        },
        "MoveToGoal.Policy.ExtrinsicReward.mean": {
            "value": -4.941520348787308,
            "min": -10.545846836068309,
            "max": -4.574920336008072,
            "count": 72
        },
        "MoveToGoal.Policy.ExtrinsicReward.sum": {
            "value": -123.5380087196827,
            "min": -282.02751847729087,
            "max": -104.0000073723495,
            "count": 72
        },
        "MoveToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 72
        },
        "MoveToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 72
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1708544320",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Marc\\Documents\\Unity\\ShoppingCart\\venv\\Scripts\\mlagents-learn config/configuration.yaml --run-id=agent_higherreward01",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1708552114"
    },
    "total": 7793.6025647,
    "count": 1,
    "self": 0.007801400000062131,
    "children": {
        "run_training.setup": {
            "total": 0.08331099999999991,
            "count": 1,
            "self": 0.08331099999999991
        },
        "TrainerController.start_learning": {
            "total": 7793.511452299999,
            "count": 1,
            "self": 8.44119229977241,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.421531599999999,
                    "count": 1,
                    "self": 7.421531599999999
                },
                "TrainerController.advance": {
                    "total": 7777.567335000228,
                    "count": 515686,
                    "self": 7.928689200353801,
                    "children": {
                        "env_step": {
                            "total": 6290.177006699868,
                            "count": 515686,
                            "self": 4730.756092899774,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1554.1788495001124,
                                    "count": 515686,
                                    "self": 22.57340950009211,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1531.6054400000203,
                                            "count": 514969,
                                            "self": 1531.6054400000203
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 5.242064299981481,
                                    "count": 515685,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 7776.414268200028,
                                            "count": 515685,
                                            "is_parallel": true,
                                            "self": 3499.1966699997856,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0008123000000006542,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0002935999999991168,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0005187000000015374,
                                                            "count": 6,
                                                            "is_parallel": true,
                                                            "self": 0.0005187000000015374
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4277.216785900243,
                                                    "count": 515685,
                                                    "is_parallel": true,
                                                    "self": 54.048467400340996,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 54.865176099971045,
                                                            "count": 515685,
                                                            "is_parallel": true,
                                                            "self": 54.865176099971045
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3984.4034758001594,
                                                            "count": 515685,
                                                            "is_parallel": true,
                                                            "self": 3984.4034758001594
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 183.89966659977173,
                                                            "count": 515685,
                                                            "is_parallel": true,
                                                            "self": 73.76993909931208,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 110.12972750045965,
                                                                    "count": 3094110,
                                                                    "is_parallel": true,
                                                                    "self": 110.12972750045965
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1479.4616391000059,
                            "count": 515685,
                            "self": 11.416669700041439,
                            "children": {
                                "process_trajectory": {
                                    "total": 261.53339379994173,
                                    "count": 515685,
                                    "self": 261.1208073999417,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.41258640000000923,
                                            "count": 7,
                                            "self": 0.41258640000000923
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1206.5115756000228,
                                    "count": 3138,
                                    "self": 464.2233971000345,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 742.2881784999882,
                                            "count": 81258,
                                            "self": 742.2881784999882
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.0999992809956893e-06,
                    "count": 1,
                    "self": 1.0999992809956893e-06
                },
                "TrainerController._save_models": {
                    "total": 0.08139229999960662,
                    "count": 1,
                    "self": 0.015388599999823782,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06600369999978284,
                            "count": 1,
                            "self": 0.06600369999978284
                        }
                    }
                }
            }
        }
    }
}